{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e82b5122",
   "metadata": {},
   "source": [
    "# Tutorial: Time-varying Extension of $\\texttt{JKOnet}^\\ast$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ac200",
   "metadata": {},
   "source": [
    "The purpose of this tutorial is to analyze the different approaches of extending $\\texttt{JKOnet}^\\ast$ to learn time-varying potentials. We will use interactive widgets to allow you to experiment with different configurations and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a40676c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:42:53.306565200Z",
     "start_time": "2024-09-25T14:42:50.542601600Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, vmap\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from flax import linen as nn\n",
    "from typing import Any, Callable, Sequence\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2914b99",
   "metadata": {},
   "source": [
    "## Define the Real Potential Function\n",
    "We deliberately select a discontinuous potential to simplify the learning process. The discontinuous nature of the potential provides clear and distinct shifts in value, making it easier to detect and model changes over time. We use `jax.lax.cond` instead of standard Python `if` statements because it enables differentiable conditional logic within JAX. While Python `if` only executes one branch and disrupts JAX's automatic differentiation, `jax.lax.cond` evaluates both branches and selects the appropriate one. This ensures that the entire computation remains differentiable, making it compatible with functions like `jax.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4a1676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:42:53.321635500Z",
     "start_time": "2024-09-25T14:42:53.305564800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Potential Function\n",
    "def V_real(x, t):\n",
    "    condition1 = (0.2 <= t) & (t <= 0.3)\n",
    "    condition2 = (0.7 <= t) & (t <= 0.8)\n",
    "    condition = condition1 | condition2\n",
    "    return jax.lax.cond(condition, lambda _: 0.0 * x, lambda _: -0.75 * x**2, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62505bfa",
   "metadata": {},
   "source": [
    "## Define the Multi-Layer Perceptron (MLP)\n",
    "Here we define our MLP architecture using Flax's linen module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6341b1c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:42:53.359806200Z",
     "start_time": "2024-09-25T14:42:53.326635300Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLP Model Definition\n",
    "class MLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, feat in enumerate(self.features):\n",
    "            x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
    "            if i != len(self.features) - 1:\n",
    "                x = nn.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c14743",
   "metadata": {},
   "source": [
    "## Generation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443d6201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:42:54.495474500Z",
     "start_time": "2024-09-25T14:42:54.468470700Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_training_trajectories(potential, initial_conditions, t_values, tau):\n",
    "    num_trajectories = len(initial_conditions)\n",
    "    timesteps = len(t_values)\n",
    "    trajectories = jnp.zeros((num_trajectories, timesteps))\n",
    "    trajectories = trajectories.at[:, 0].set(initial_conditions)\n",
    "\n",
    "    for i in range(1, timesteps):\n",
    "        x_prev = trajectories[:, i - 1]\n",
    "        t_prev = t_values[i - 1]\n",
    "        grad_x = vmap(lambda x: grad(potential, argnums=0)(x, t_prev))(x_prev)\n",
    "        x_next = x_prev - tau * grad_x\n",
    "        trajectories = trajectories.at[:, i].set(x_next)\n",
    "\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862a716",
   "metadata": {},
   "source": [
    "## Generation of predicted trajectories\n",
    "We explore two methods for generating predicted trajectories: implicit and explicit schemes. The implicit method updates the position using the gradient of the potential at the future state, while the explicit method uses the gradient at the current state. The equations for each approach are shown below:\n",
    "\n",
    "Implicit scheme:\n",
    "$$\n",
    "x_{t+1} = x_{t} - \\tau \\nabla V(x_{t+1}, t+1).\n",
    "$$\n",
    "\n",
    "Explicit scheme:\n",
    "$$\n",
    "x_{t+1} = x_{t} - \\tau \\nabla V(x_{t}, t).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2eab55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:42:55.874613600Z",
     "start_time": "2024-09-25T14:42:55.850384300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper Functions for Trajectory Generation\n",
    "def generate_pred_trajectories_explicit(potential, params, x_initials, t_values, tau):\n",
    "    num_trajectories = len(x_initials)\n",
    "    num_timesteps = len(t_values)\n",
    "    \n",
    "    trajectories = jnp.zeros((num_trajectories, num_timesteps))\n",
    "    \n",
    "    trajectories = trajectories.at[:, 0].set(x_initials)\n",
    "    \n",
    "    for i in range(1, num_timesteps):\n",
    "        t_prev = t_values[i - 1]\n",
    "        \n",
    "        for j in range(num_trajectories):\n",
    "            x_prev = trajectories[j, i - 1]\n",
    "            grad_x = grad(lambda x: potential(params, x, t_prev))(x_prev)\n",
    "            x_next = x_prev - tau * grad_x\n",
    "            trajectories = trajectories.at[j, i].set(x_next)\n",
    "        \n",
    "    return trajectories\n",
    "\n",
    "def generate_pred_trajectories_implicit(potential, params, x_initials, t_values, tau):\n",
    "    def implicit_eq(x_next, x_prev, t_next):\n",
    "        return x_next - x_prev + tau * grad(lambda x: potential(params, x, t_next))(x_next)\n",
    "    \n",
    "    num_trajectories = len(x_initials)\n",
    "    trajectory_length = len(t_values)\n",
    "    \n",
    "    # Initialize a zero array to store all trajectories\n",
    "    trajectories = jnp.zeros((num_trajectories, trajectory_length))\n",
    "    \n",
    "    for idx, x_initial in enumerate(x_initials):\n",
    "        x_learned_trajectory = jnp.zeros_like(t_values)\n",
    "        x_learned_trajectory = x_learned_trajectory.at[0].set(x_initial)\n",
    "        \n",
    "        for i in range(1, trajectory_length):\n",
    "            x_prev = x_learned_trajectory[i - 1]\n",
    "            t_next = t_values[i]\n",
    "            \n",
    "            # Perform Newton-Raphson step to find the next x\n",
    "            x_next = newton_raphson_step(lambda x_next: implicit_eq(x_next, x_prev, t_next), x_prev)\n",
    "            x_learned_trajectory = x_learned_trajectory.at[i].set(x_next)\n",
    "        \n",
    "        # Store the trajectory\n",
    "        trajectories = trajectories.at[idx].set(x_learned_trajectory)\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "def newton_raphson_step(f, x0, tol=1e-5, max_iter=100):\n",
    "    def body_fun(val):\n",
    "        x0, fx, iter_count = val\n",
    "        dfx = grad(f)(x0)\n",
    "        x0 = x0 - fx / dfx\n",
    "        iter_count += 1\n",
    "        return x0, f(x0), iter_count\n",
    "\n",
    "    def cond_fun(val):\n",
    "        _, fx, iter_count = val\n",
    "        return (jnp.abs(fx) >= tol) & (iter_count < max_iter)\n",
    "\n",
    "    x0, fx, iter_count = jax.lax.while_loop(cond_fun, body_fun, (x0, f(x0), 0))\n",
    "    return x0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fde55f",
   "metadata": {},
   "source": [
    "## Loss scheme\n",
    "We must also introduce time in the loss equation. The first approach involves evaluating the potential in the loss function at the last time step, resulting in a fully implicit scheme. This means that the loss captures the relationship between the predicted trajectories and the potential's gradient at the subsequent time.\n",
    "\n",
    "Implicit in time loss scheme:\n",
    "$$\n",
    "\\sum_{t=0}^{T-1} \\int_{\\mathbb{R}^d \\times \\mathbb{R}^d} \\left\\| \n",
    "    \\nabla V(x_{t+1}, t+1) + \\frac{1}{\\tau}(x_{t+1}-x_t) \n",
    "\\right\\|^2 \\mathrm{d}\\gamma_t(x_t, x_{t+1}).\n",
    "$$\n",
    "\n",
    "The second choice is to evaluate the potential at the previous time step in the loss equation,\n",
    "which would result in a scheme implicit in space and explicit in time.\n",
    "\n",
    "Explicit in time loss scheme:\n",
    "\n",
    "$$\n",
    "\\sum_{t=0}^{T-1} \\int_{\\mathbb{R}^d \\times \\mathbb{R}^d} \\left\\| \n",
    "    \\nabla V(x_{t+1}, t) + \\frac{1}{\\tau}(x_{t+1}-x_t) \n",
    "\\right\\|^2 \\mathrm{d}\\gamma_t(x_t, x_{t+1}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f81145",
   "metadata": {},
   "source": [
    "## Main Function: `plot_trajectories`\n",
    "\n",
    "This function takes several parameters related to the trajectory prediction scheme and performs the following tasks:\n",
    "1. **Generates Trajectories**: Creates training trajectories.\n",
    "2. **Subsampling**: Reduces the number of data points based on the selected subsampling rate. This affects the size of the time step, which accentuates the difference between schemes.\n",
    "3. **Model Initialization**: Sets up the machine learning model and optimizer.\n",
    "4. **Training**: Trains the model over a specified number of epochs.\n",
    "5. **Prediction and Visualization**: Compares learned trajectories with real trajectories.\n",
    "\n",
    "Here’s the code for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf6694c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:43:01.969278Z",
     "start_time": "2024-09-25T14:43:01.949875800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main Function for Interactive Plotting\n",
    "def plot_trajectories(traj_scheme, loss_scheme, subsampling_rate, learning_rate, num_epochs, num_trajectories):\n",
    "    key = random.PRNGKey(42)\n",
    "    timesteps = 50\n",
    "    x_initials = random.uniform(key, (num_trajectories,), minval=0.7, maxval=1.3)\n",
    "    t_values = jnp.linspace(0, 1, timesteps)\n",
    "    tau = t_values[1] - t_values[0]\n",
    "    x_trajectories = generate_training_trajectories(V_real, x_initials, t_values, tau)\n",
    "    \n",
    "    # Subsampling\n",
    "    x_trajectories_sub = jnp.array([trajectory[::subsampling_rate] for trajectory in x_trajectories])\n",
    "    t_values_sub = t_values[::subsampling_rate]\n",
    "\n",
    "    # Training data preparation\n",
    "    y_batch = x_trajectories_sub[:, 1:]\n",
    "    x_batch = x_trajectories_sub[:, :-1]\n",
    "    t_x = jnp.tile(t_values_sub[:-1], (num_trajectories, 1))\n",
    "    t_y = jnp.tile(t_values_sub[1:], (num_trajectories, 1))\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    key = random.PRNGKey(0)\n",
    "    input_shape = (2,)\n",
    "    features = [20, 20, 1]\n",
    "    model = MLP(features)\n",
    "    params = model.init(key, jnp.ones(input_shape))\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    def aux_fun(params, x, t):\n",
    "        inputs = jnp.concatenate([x[..., None], t[..., None]], axis=-1)\n",
    "        return model.apply(params, inputs).squeeze()\n",
    "\n",
    "    grad_model = grad(aux_fun, argnums=1)\n",
    "\n",
    "    def mlp_loss(params, x, y, t):\n",
    "        return jnp.mean(jnp.square(y - x + tau * vmap(grad_model, in_axes=(None, 0, 0))(params, y, t)))\n",
    "\n",
    "    x_concatenated = jnp.concatenate(x_batch)\n",
    "    y_concatenated = jnp.concatenate(y_batch)\n",
    "    t_x_concatenated = jnp.concatenate(t_x)\n",
    "    t_y_concatenated = jnp.concatenate(t_y)\n",
    "    \n",
    "    #Depending on the scheme, we will use the previous time step or the next time step in the loss expression\n",
    "    if loss_scheme == 'Explicit':\n",
    "        t_concatenated = t_x_concatenated\n",
    "    else:\n",
    "        t_concatenated = t_y_concatenated\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, grads = jax.value_and_grad(mlp_loss)(params, x_concatenated, y_concatenated, t_concatenated)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    # Prediction and Plotting\n",
    "    x_initial = x_trajectories_sub[:1][:, 0]\n",
    "    \n",
    "    if traj_scheme == 'Explicit':\n",
    "        trajectories_pred = generate_pred_trajectories_explicit(aux_fun, params, x_initial, t_values_sub, tau)\n",
    "    else:\n",
    "        trajectories_pred = generate_pred_trajectories_implicit(aux_fun, params, x_initial, t_values_sub, tau)\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(t_values_sub, trajectories_pred[0], label='Learned Trajectory', linestyle='--', marker='o')\n",
    "    plt.plot(t_values, x_trajectories[0], label='Real Trajectory', linestyle='-', marker='x')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('X')\n",
    "    plt.title('Comparison of Learned and Real Trajectories')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b31443",
   "metadata": {},
   "source": [
    "## Interactive Widgets\n",
    "\n",
    "The following widgets allow you to customize the parameters used. \n",
    "\n",
    "- **Prediction Scheme**: Choose between `Explicit` and `Implicit` methods for trajectory prediction.\n",
    "- **Loss Scheme**: Choose between `Explicit` and `Implicit` in time loss equation.\n",
    "- **Subsampling Rate**: Adjust how many data points to skip during training. Adjust time step size.\n",
    "- **Learning Rate**: Set the step size for the optimizer.\n",
    "- **Number of Epochs**: Define how many iterations the model should train.\n",
    "- **Number of Trajectories**: Specify how many trajectories. Amount of training data.\n",
    "\n",
    "Here are the widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee52ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:43:03.397290700Z",
     "start_time": "2024-09-25T14:43:03.317770200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Widgets for Interaction\n",
    "traj_scheme_widget = widgets.Dropdown(\n",
    "    options=['Explicit', 'Implicit'],\n",
    "    value='Implicit',\n",
    "    description='Prediction Scheme:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "loss_scheme_widget = widgets.Dropdown(\n",
    "    options=['Explicit', 'Implicit'],\n",
    "    value='Implicit',\n",
    "    description='Loss Scheme (time):',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "subsampling_rate_widget = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=5,\n",
    "    step=1,\n",
    "    description='Subsampling:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "learning_rate_widget = widgets.FloatSlider(\n",
    "    value=0.05,\n",
    "    min=0.001,\n",
    "    max=0.1,\n",
    "    step=0.001,\n",
    "    description='Learning Rate:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "num_epochs_widget = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=100,\n",
    "    max=10000,\n",
    "    step=100,\n",
    "    description='Epochs:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "num_trajectories_widget = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='Trajectories:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button to Update Plot\n",
    "plot_button = widgets.Button(\n",
    "    description='Update Plot',\n",
    "    disabled=False,\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "# Callback Function for Button Click\n",
    "def on_plot_button_clicked(b):\n",
    "    \n",
    "    with output:\n",
    "        # Clear previous output in the output widget\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Call the plot function with updated parameters\n",
    "        plot_trajectories(traj_scheme_widget.value,\n",
    "                          loss_scheme_widget.value,\n",
    "                          subsampling_rate_widget.value,\n",
    "                          learning_rate_widget.value,\n",
    "                          num_epochs_widget.value,\n",
    "                          num_trajectories_widget.value)\n",
    "\n",
    "plot_button.on_click(on_plot_button_clicked)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f980b4c",
   "metadata": {},
   "source": [
    "## Update Plot Button\n",
    "\n",
    "The button below will update the plot with the selected parameters when clicked. The callback function handles the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b8f854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:43:04.531133900Z",
     "start_time": "2024-09-25T14:43:04.462876300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf9b690c366463fa55ac53352d532ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Prediction Scheme:', index=1, options=('Explicit', 'Implicit'), value='Implicit')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570cb7df153b41f3a4b44028e872439a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Loss Scheme (time):', index=1, options=('Explicit', 'Implicit'), value='Implicit')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45914a05128d49b0a328349db4ae112f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=5, description='Subsampling:', max=5, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f214d74a7a545a9942acb1baf9e967e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.05, description='Learning Rate:', max=0.1, min=0.001, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3757f9d28ea94201890183f4230f3eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Epochs:', max=10000, min=100, step=100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca2732ab4de41c39f974a1f123cb4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Trajectories:', max=50, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b94cf8d9b24e82974786ae32faebf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Update Plot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc6d4c23d8a4223952d173b9dbda7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(traj_scheme_widget, loss_scheme_widget, subsampling_rate_widget, learning_rate_widget, num_epochs_widget, num_trajectories_widget, plot_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39846c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
